{
  "metadata": {
    "timestamp_utc": "2025-08-08T15:17:19Z",
    "batch_size_eval": 32,
    "candidate_k_eval": 50,
    "experiment_prefix": "RERANK_hybrid",
    "retrieval_top_k": 5,
    "candidate_k": 50,
    "base_retriever": {
      "type": "hybrid",
      "hybrid": {
        "rrf_k": 60,
        "dense_weight": 1.0,
        "sparse_weight": 1.0
      },
      "dense": {
        "impl": "DenseRetriever",
        "device": "cpu"
      },
      "bm25": {
        "use_stopwords": true,
        "use_stemming": true,
        "k1": 1.5,
        "b": 0.75,
        "corpus": {
          "num_chunks": 801,
          "min_len": 4,
          "max_len": 2687,
          "avg_len": 91.82521847690387
        }
      }
    },
    "reranker": {
      "reranker_model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
      "device": "cpu",
      "max_length": 256,
      "batch_size": 64,
      "max_rerank_candidates": 20,
      "default_strategy": "cross_encoder",
      "fast_mode_default": true
    },
    "rerank_strategy": "cross_encoder",
    "dataset": "singlehop"
  },
  "metrics": {
    "num_queries": 508,
    "avg_precision@k": 0.08700787401574803,
    "avg_recall@k": 0.43503937007874016,
    "avg_mrr": 0.24701443569553805,
    "avg_ndcg@k": 0.29334203735807596,
    "avg_ap@k": 0.24701443569553805,
    "avg_retrieval_time": 1.679298942323818
  }
}