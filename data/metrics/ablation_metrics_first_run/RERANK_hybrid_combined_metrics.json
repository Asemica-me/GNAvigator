{
  "metadata": {
    "timestamp_utc": "2025-08-08T15:30:32Z",
    "batch_size_eval": 32,
    "candidate_k_eval": 50,
    "experiment_prefix": "RERANK_hybrid",
    "retrieval_top_k": 5,
    "candidate_k": 50,
    "base_retriever": {
      "type": "hybrid",
      "hybrid": {
        "rrf_k": 60,
        "dense_weight": 1.0,
        "sparse_weight": 1.0
      },
      "dense": {
        "impl": "DenseRetriever",
        "device": "cpu"
      },
      "bm25": {
        "use_stopwords": true,
        "use_stemming": true,
        "k1": 1.5,
        "b": 0.75,
        "corpus": {
          "num_chunks": 801,
          "min_len": 4,
          "max_len": 2687,
          "avg_len": 91.82521847690387
        }
      }
    },
    "reranker": {
      "reranker_model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
      "device": "cpu",
      "max_length": 256,
      "batch_size": 64,
      "max_rerank_candidates": 20,
      "default_strategy": "cross_encoder",
      "fast_mode_default": true
    },
    "rerank_strategy": "cross_encoder",
    "dataset": "combined",
    "combined_sources": [
      "singlehop",
      "multihop"
    ],
    "shuffle": true
  },
  "metrics": {
    "num_queries": 908,
    "avg_precision@k": 0.09603524229074889,
    "avg_recall@k": 0.3306718061674009,
    "avg_mrr": 0.2636563876651982,
    "avg_ndcg@k": 0.3126739355663104,
    "avg_ap@k": 0.18704570484581498,
    "avg_retrieval_time": 0.8726460719168276
  }
}