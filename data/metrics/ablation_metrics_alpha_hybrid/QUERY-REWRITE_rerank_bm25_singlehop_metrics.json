{
  "metadata": {
    "timestamp_utc": "2025-08-08T23:47:16Z",
    "batch_size_eval": 32,
    "candidate_k_eval": 50,
    "experiment_prefix": "QUERY-REWRITE_rerank_bm25",
    "retrieval_top_k": 5,
    "candidate_k": 50,
    "query_rewriter": {
      "strategy_flags": {
        "enable_cce": true,
        "enable_kwr": true,
        "enable_gqr": true,
        "enable_prf": false,
        "enable_decompose": true
      },
      "expansion_terms": 3,
      "lang": "italian",
      "device": "cpu",
      "base_retriever": {
        "type": "rerank_bm25",
        "bm25": {
          "use_stopwords": true,
          "use_stemming": true,
          "k1": 1.5,
          "b": 0.75,
          "corpus": {
            "num_chunks": 801,
            "min_len": 4,
            "max_len": 2687,
            "avg_len": 91.82521847690387
          }
        },
        "reranker": {
          "reranker_model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
          "device": "cpu",
          "max_length": 256,
          "batch_size": 64,
          "max_rerank_candidates": 20
        }
      },
      "reranker": {
        "reranker_model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
        "device": "cpu",
        "max_length": 256,
        "batch_size": 64,
        "max_rerank_candidates": 20
      }
    },
    "dataset": "singlehop"
  },
  "metrics": {
    "num_queries": 508,
    "avg_precision@k": 0.08779527559055118,
    "avg_recall@k": 0.4389763779527559,
    "avg_mrr": 0.2587270341207349,
    "avg_ndcg@k": 0.3035219109910378,
    "avg_ap@k": 0.2587270341207349,
    "avg_retrieval_time": 10.025438646064048
  }
}