{
  "metadata": {
    "timestamp_utc": "2025-08-10T22:11:24Z",
    "batch_size_eval": 16,
    "candidate_k_eval": 20,
    "experiment_prefix": "RERANK_hybrid",
    "retrieval_top_k": 5,
    "candidate_k": 20,
    "base_retriever": {
      "type": "hybrid",
      "hybrid": {
        "rrf_k": 60,
        "dense_weight": null,
        "sparse_weight": null
      },
      "dense": {
        "impl": "DenseRetriever",
        "device": "cpu"
      },
      "bm25": {
        "use_stopwords": true,
        "use_stemming": true,
        "k1": 1.5,
        "b": 0.75,
        "corpus": {
          "num_chunks": 801,
          "min_len": 4,
          "max_len": 2687,
          "avg_len": 91.82521847690387
        }
      }
    },
    "reranker": {
      "reranker_model": "cross-encoder/ms-marco-MiniLM-L-2-v2",
      "device": "cpu",
      "max_length": 512,
      "batch_size": 8,
      "max_rerank_candidates": 20,
      "default_strategy": "cross_encoder",
      "fast_mode_default": true
    },
    "rerank_strategy": "cross_encoder",
    "dataset": "singlehop"
  },
  "metrics": {
    "num_queries": 508,
    "avg_precision@k": 0.05196850393700787,
    "avg_recall@k": 0.25984251968503935,
    "avg_mrr": 0.11194225721784776,
    "avg_ndcg@k": 0.14826945045579976,
    "avg_ap@k": 0.11194225721784776,
    "avg_retrieval_time": 0.7241779283435252
  }
}